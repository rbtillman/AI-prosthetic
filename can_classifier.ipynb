{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91aff5cd-15b9-430a-b5e0-af315d0b1b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96f9712c-23fe-490b-a4a8-0e503b0af073",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-17 13:40:21.957375: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-17 13:40:25.048806: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1737150026.708037   94864 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1737150027.045665   94864 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-17 13:40:29.495190: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "libraries import completed in142.23748993873596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "import math\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, InputLayer, Dropout, Conv1D, Flatten, Reshape, MaxPooling1D, BatchNormalization,\n",
    "    Conv2D, GlobalMaxPooling2D, Lambda, GlobalAveragePooling2D)\n",
    "from tensorflow.keras.optimizers import Adam, Adadelta\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pathlib import Path\n",
    "load_time = time.time() - start_time\n",
    "print(f\"\\nlibraries import completed in{load_time}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "768a9806-43c1-4548-8e64-89cde966e159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 361 files belonging to 3 classes.\n",
      "Found 92 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Constants and paths\n",
    "WEIGHTS_PATH = './transfer-learning-weights/edgeimpulse/MobileNetV2.0_35.96x96.grayscale.bsize_64.lr_0_005.epoch_260.val_loss_3.10.val_accuracy_0.35.hdf5'\n",
    "ROOT_URL = 'https://cdn.edgeimpulse.com/'\n",
    "INPUT_SHAPE = (96, 96, 1)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 40\n",
    "LEARNING_RATE = 0.0005\n",
    "FINE_TUNE_EPOCHS = 15\n",
    "FINE_TUNE_PERCENTAGE = 65\n",
    "TRAIN_DIR = './CANS-DATA/TRAIN'  # Update this with your train dataset directory\n",
    "VALIDATION_DIR = './CANS-DATA/TEST'  # Update this with your validation dataset directory\n",
    "\n",
    "# Download pretrained weights if not available\n",
    "p = Path(WEIGHTS_PATH)\n",
    "if not p.exists():\n",
    "    print(f\"Pretrained weights {WEIGHTS_PATH} unavailable; downloading...\")\n",
    "    if not p.parent.exists():\n",
    "        p.parent.mkdir(parents=True)\n",
    "    weights_data = requests.get(ROOT_URL + WEIGHTS_PATH[2:]).content\n",
    "    with open(WEIGHTS_PATH, 'wb') as f:\n",
    "        f.write(weights_data)\n",
    "    print(f\"Pretrained weights {WEIGHTS_PATH} downloaded successfully.\")\n",
    "\n",
    "# Load dataset\n",
    "# train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#     TRAIN_DIR,\n",
    "#     image_size=INPUT_SHAPE[:2],\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     label_mode='categorical'\n",
    "# )\n",
    "\n",
    "# validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#     VALIDATION_DIR,\n",
    "#     image_size=INPUT_SHAPE[:2],\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     label_mode='categorical'\n",
    "# )\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    image_size=(96, 96),  # Resize images to 96x96\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='grayscale',  # Ensure images are grayscale\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    VALIDATION_DIR,\n",
    "    image_size=(96, 96),  # Resize validation images to 96x96\n",
    "    batch_size=BATCH_SIZE,\n",
    "    color_mode='grayscale',  # Ensure validation images are grayscale\n",
    "    label_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9229eb4f-9758-4bae-9aba-0f11addb60c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model loaded\n",
      "Training the model...\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/rtill/AI-venv/AIvenv/lib/python3.12/site-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor_2010']\n",
      "Received: inputs=Tensor(shape=(None, 96, 96, 1))\n",
      "  warnings.warn(msg)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 41s - 3s/step - accuracy: 0.5845 - loss: 0.9651 - val_accuracy: 0.3913 - val_loss: 1.0559\n",
      "Epoch 2/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 1s - 101ms/step - accuracy: 0.8892 - loss: 0.2957 - val_accuracy: 0.4674 - val_loss: 1.0433\n",
      "Epoch 3/80\n",
      "12/12 - 0s - 38ms/step - accuracy: 0.9391 - loss: 0.1642 - val_accuracy: 0.4239 - val_loss: 1.5490\n",
      "Epoch 4/80\n",
      "12/12 - 0s - 32ms/step - accuracy: 0.9640 - loss: 0.0857 - val_accuracy: 0.4348 - val_loss: 1.9611\n",
      "Epoch 5/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 1s - 95ms/step - accuracy: 0.9917 - loss: 0.0435 - val_accuracy: 0.5435 - val_loss: 1.4638\n",
      "Epoch 6/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 1s - 82ms/step - accuracy: 1.0000 - loss: 0.0306 - val_accuracy: 0.6087 - val_loss: 1.1948\n",
      "Epoch 7/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 1s - 85ms/step - accuracy: 0.9889 - loss: 0.0443 - val_accuracy: 0.6630 - val_loss: 1.0315\n",
      "Epoch 8/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 1s - 82ms/step - accuracy: 0.9834 - loss: 0.0308 - val_accuracy: 0.7065 - val_loss: 0.8546\n",
      "Epoch 9/80\n",
      "12/12 - 1s - 66ms/step - accuracy: 0.9945 - loss: 0.0168 - val_accuracy: 0.6630 - val_loss: 1.0138\n",
      "Epoch 10/80\n",
      "12/12 - 1s - 45ms/step - accuracy: 0.9861 - loss: 0.0268 - val_accuracy: 0.5326 - val_loss: 2.0069\n",
      "Epoch 11/80\n",
      "12/12 - 1s - 42ms/step - accuracy: 0.9834 - loss: 0.0627 - val_accuracy: 0.6413 - val_loss: 1.4154\n",
      "Epoch 12/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 1s - 119ms/step - accuracy: 0.9695 - loss: 0.0643 - val_accuracy: 0.8370 - val_loss: 0.5237\n",
      "Epoch 13/80\n",
      "12/12 - 1s - 43ms/step - accuracy: 0.9889 - loss: 0.0731 - val_accuracy: 0.7826 - val_loss: 0.7055\n",
      "Epoch 14/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 1s - 91ms/step - accuracy: 0.9861 - loss: 0.0491 - val_accuracy: 0.8587 - val_loss: 0.5361\n",
      "Epoch 15/80\n",
      "12/12 - 0s - 37ms/step - accuracy: 0.9806 - loss: 0.0635 - val_accuracy: 0.7826 - val_loss: 0.6075\n",
      "Epoch 16/80\n",
      "12/12 - 0s - 39ms/step - accuracy: 0.9584 - loss: 0.1341 - val_accuracy: 0.7174 - val_loss: 0.9965\n",
      "Epoch 17/80\n",
      "12/12 - 1s - 42ms/step - accuracy: 0.9751 - loss: 0.0740 - val_accuracy: 0.7717 - val_loss: 0.7005\n",
      "Epoch 18/80\n",
      "12/12 - 0s - 39ms/step - accuracy: 0.9861 - loss: 0.0333 - val_accuracy: 0.8152 - val_loss: 0.7816\n",
      "Epoch 19/80\n",
      "12/12 - 1s - 45ms/step - accuracy: 0.9834 - loss: 0.0364 - val_accuracy: 0.8261 - val_loss: 0.6703\n",
      "Epoch 20/80\n",
      "12/12 - 0s - 39ms/step - accuracy: 0.9917 - loss: 0.0271 - val_accuracy: 0.7609 - val_loss: 0.6499\n",
      "Epoch 21/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 1s - 103ms/step - accuracy: 0.9917 - loss: 0.0347 - val_accuracy: 0.8804 - val_loss: 0.3722\n",
      "Epoch 22/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 1s - 92ms/step - accuracy: 0.9972 - loss: 0.0128 - val_accuracy: 0.8913 - val_loss: 0.3311\n",
      "Epoch 23/80\n",
      "12/12 - 1s - 46ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.8913 - val_loss: 0.3498\n",
      "Epoch 24/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 1s - 104ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9130 - val_loss: 0.3279\n",
      "Epoch 25/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 1s - 119ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9239 - val_loss: 0.3260\n",
      "Epoch 26/80\n",
      "12/12 - 0s - 36ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.9130 - val_loss: 0.3752\n",
      "Epoch 27/80\n",
      "12/12 - 0s - 39ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9130 - val_loss: 0.3836\n",
      "Epoch 28/80\n",
      "12/12 - 0s - 41ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.9239 - val_loss: 0.3391\n",
      "Epoch 29/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 1s - 95ms/step - accuracy: 0.9972 - loss: 0.0090 - val_accuracy: 0.9348 - val_loss: 0.2684\n",
      "Epoch 30/80\n",
      "12/12 - 1s - 45ms/step - accuracy: 0.9945 - loss: 0.0141 - val_accuracy: 0.9022 - val_loss: 0.2697\n",
      "Epoch 31/80\n",
      "12/12 - 0s - 33ms/step - accuracy: 0.9917 - loss: 0.0244 - val_accuracy: 0.9130 - val_loss: 0.2424\n",
      "Epoch 32/80\n",
      "12/12 - 1s - 44ms/step - accuracy: 0.9945 - loss: 0.0206 - val_accuracy: 0.9239 - val_loss: 0.2583\n",
      "Epoch 33/80\n",
      "12/12 - 0s - 40ms/step - accuracy: 0.9972 - loss: 0.0163 - val_accuracy: 0.8804 - val_loss: 0.3651\n",
      "Epoch 34/80\n",
      "12/12 - 1s - 44ms/step - accuracy: 0.9972 - loss: 0.0094 - val_accuracy: 0.8696 - val_loss: 0.4346\n",
      "Epoch 35/80\n",
      "12/12 - 0s - 35ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.8913 - val_loss: 0.4243\n",
      "Epoch 36/80\n",
      "12/12 - 1s - 46ms/step - accuracy: 0.9972 - loss: 0.0054 - val_accuracy: 0.9130 - val_loss: 0.4145\n",
      "Epoch 37/80\n",
      "12/12 - 0s - 32ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9130 - val_loss: 0.4295\n",
      "Epoch 38/80\n",
      "12/12 - 0s - 37ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.9239 - val_loss: 0.4452\n",
      "Epoch 39/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 1s - 116ms/step - accuracy: 0.9917 - loss: 0.0398 - val_accuracy: 0.9457 - val_loss: 0.2050\n",
      "Epoch 40/80\n",
      "12/12 - 2s - 141ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.8261 - val_loss: 0.7498\n",
      "Epoch 41/80\n",
      "12/12 - 0s - 35ms/step - accuracy: 0.9889 - loss: 0.0242 - val_accuracy: 0.8804 - val_loss: 0.3941\n",
      "Epoch 42/80\n",
      "12/12 - 0s - 32ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.9022 - val_loss: 0.3716\n",
      "Epoch 43/80\n",
      "12/12 - 0s - 42ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.8370 - val_loss: 0.7490\n",
      "Epoch 44/80\n",
      "12/12 - 0s - 31ms/step - accuracy: 0.9972 - loss: 0.0112 - val_accuracy: 0.8804 - val_loss: 0.5855\n",
      "Epoch 45/80\n",
      "12/12 - 0s - 35ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9239 - val_loss: 0.4738\n",
      "Epoch 46/80\n",
      "12/12 - 0s - 32ms/step - accuracy: 0.9972 - loss: 0.0079 - val_accuracy: 0.9239 - val_loss: 0.5017\n",
      "Epoch 47/80\n",
      "12/12 - 0s - 37ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9130 - val_loss: 0.4814\n",
      "Epoch 48/80\n",
      "12/12 - 0s - 39ms/step - accuracy: 0.9972 - loss: 0.0066 - val_accuracy: 0.8913 - val_loss: 0.5850\n",
      "Epoch 49/80\n",
      "12/12 - 0s - 38ms/step - accuracy: 0.9972 - loss: 0.0134 - val_accuracy: 0.8370 - val_loss: 0.7725\n",
      "Epoch 50/80\n",
      "12/12 - 0s - 41ms/step - accuracy: 0.9972 - loss: 0.0156 - val_accuracy: 0.7500 - val_loss: 1.2727\n",
      "Epoch 51/80\n",
      "12/12 - 0s - 38ms/step - accuracy: 0.9889 - loss: 0.0334 - val_accuracy: 0.8043 - val_loss: 1.0560\n",
      "Epoch 52/80\n",
      "12/12 - 1s - 47ms/step - accuracy: 0.9972 - loss: 0.0068 - val_accuracy: 0.8261 - val_loss: 0.9072\n",
      "Epoch 53/80\n",
      "12/12 - 1s - 45ms/step - accuracy: 0.9972 - loss: 0.0063 - val_accuracy: 0.8587 - val_loss: 0.7701\n",
      "Epoch 54/80\n",
      "12/12 - 0s - 37ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.8478 - val_loss: 0.6515\n",
      "Epoch 55/80\n",
      "12/12 - 0s - 32ms/step - accuracy: 0.9945 - loss: 0.0071 - val_accuracy: 0.8913 - val_loss: 0.4606\n",
      "Epoch 56/80\n",
      "12/12 - 0s - 35ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9022 - val_loss: 0.4776\n",
      "Epoch 57/80\n",
      "12/12 - 0s - 32ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.8804 - val_loss: 0.8684\n",
      "Epoch 58/80\n",
      "12/12 - 0s - 33ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.9130 - val_loss: 0.5448\n",
      "Epoch 59/80\n",
      "12/12 - 0s - 31ms/step - accuracy: 0.9945 - loss: 0.0090 - val_accuracy: 0.9130 - val_loss: 0.4407\n",
      "Epoch 60/80\n",
      "12/12 - 0s - 31ms/step - accuracy: 0.9945 - loss: 0.0268 - val_accuracy: 0.9239 - val_loss: 0.4250\n",
      "Epoch 61/80\n",
      "12/12 - 0s - 38ms/step - accuracy: 0.9861 - loss: 0.0393 - val_accuracy: 0.8152 - val_loss: 0.8603\n",
      "Epoch 62/80\n",
      "12/12 - 0s - 33ms/step - accuracy: 0.9861 - loss: 0.0570 - val_accuracy: 0.7717 - val_loss: 1.6251\n",
      "Epoch 63/80\n",
      "12/12 - 0s - 33ms/step - accuracy: 0.9778 - loss: 0.0765 - val_accuracy: 0.7717 - val_loss: 1.6810\n",
      "Epoch 64/80\n",
      "12/12 - 0s - 33ms/step - accuracy: 0.9945 - loss: 0.0179 - val_accuracy: 0.7283 - val_loss: 1.5894\n",
      "Epoch 65/80\n",
      "12/12 - 0s - 34ms/step - accuracy: 0.9945 - loss: 0.0077 - val_accuracy: 0.8370 - val_loss: 0.7135\n",
      "Epoch 66/80\n",
      "12/12 - 1s - 43ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.8478 - val_loss: 0.7904\n",
      "Epoch 67/80\n",
      "12/12 - 0s - 33ms/step - accuracy: 0.9972 - loss: 0.0292 - val_accuracy: 0.8043 - val_loss: 1.3409\n",
      "Epoch 68/80\n",
      "12/12 - 1s - 43ms/step - accuracy: 0.9972 - loss: 0.0102 - val_accuracy: 0.7935 - val_loss: 1.4463\n",
      "Epoch 69/80\n",
      "12/12 - 0s - 34ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.7935 - val_loss: 1.3709\n",
      "Epoch 70/80\n",
      "12/12 - 1s - 42ms/step - accuracy: 0.9972 - loss: 0.0082 - val_accuracy: 0.8043 - val_loss: 1.4690\n",
      "Epoch 71/80\n",
      "12/12 - 0s - 37ms/step - accuracy: 0.9861 - loss: 0.0914 - val_accuracy: 0.6957 - val_loss: 2.9634\n",
      "Epoch 72/80\n",
      "12/12 - 0s - 39ms/step - accuracy: 0.9889 - loss: 0.0444 - val_accuracy: 0.8478 - val_loss: 0.8172\n",
      "Epoch 73/80\n",
      "12/12 - 0s - 31ms/step - accuracy: 0.9889 - loss: 0.0562 - val_accuracy: 0.9457 - val_loss: 0.4150\n",
      "Epoch 74/80\n",
      "12/12 - 0s - 40ms/step - accuracy: 0.9972 - loss: 0.0080 - val_accuracy: 0.8804 - val_loss: 0.8923\n",
      "Epoch 75/80\n",
      "12/12 - 0s - 36ms/step - accuracy: 0.9861 - loss: 0.0317 - val_accuracy: 0.8478 - val_loss: 0.9174\n",
      "Epoch 76/80\n",
      "12/12 - 0s - 33ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.8913 - val_loss: 0.6195\n",
      "Epoch 77/80\n",
      "12/12 - 0s - 35ms/step - accuracy: 0.9917 - loss: 0.0173 - val_accuracy: 0.8804 - val_loss: 0.4777\n",
      "Epoch 78/80\n",
      "12/12 - 0s - 30ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.8804 - val_loss: 0.7929\n",
      "Epoch 79/80\n",
      "12/12 - 1s - 43ms/step - accuracy: 0.9972 - loss: 0.0069 - val_accuracy: 0.8587 - val_loss: 0.8062\n",
      "Epoch 80/80\n",
      "12/12 - 0s - 39ms/step - accuracy: 0.9945 - loss: 0.0065 - val_accuracy: 0.8913 - val_loss: 0.2276\n",
      "Fine-tuning the model for 15 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "12/12 - 8s - 689ms/step - accuracy: 0.9889 - loss: 0.0295 - val_accuracy: 0.9457 - val_loss: 0.2046\n",
      "Epoch 2/15\n",
      "12/12 - 1s - 47ms/step - accuracy: 0.9972 - loss: 0.0181 - val_accuracy: 0.9457 - val_loss: 0.2040\n",
      "Epoch 3/15\n",
      "12/12 - 1s - 45ms/step - accuracy: 0.9834 - loss: 0.0257 - val_accuracy: 0.9457 - val_loss: 0.2034\n",
      "Epoch 4/15\n",
      "12/12 - 0s - 40ms/step - accuracy: 0.9972 - loss: 0.0128 - val_accuracy: 0.9457 - val_loss: 0.2029\n",
      "Epoch 5/15\n",
      "12/12 - 0s - 34ms/step - accuracy: 0.9972 - loss: 0.0270 - val_accuracy: 0.9457 - val_loss: 0.2022\n",
      "Epoch 6/15\n",
      "12/12 - 0s - 34ms/step - accuracy: 0.9889 - loss: 0.0431 - val_accuracy: 0.9457 - val_loss: 0.2016\n",
      "Epoch 7/15\n",
      "12/12 - 0s - 35ms/step - accuracy: 0.9917 - loss: 0.0144 - val_accuracy: 0.9457 - val_loss: 0.2009\n",
      "Epoch 8/15\n",
      "12/12 - 0s - 34ms/step - accuracy: 0.9889 - loss: 0.0258 - val_accuracy: 0.9457 - val_loss: 0.2010\n",
      "Epoch 9/15\n",
      "12/12 - 0s - 30ms/step - accuracy: 0.9889 - loss: 0.0264 - val_accuracy: 0.9457 - val_loss: 0.2002\n",
      "Epoch 10/15\n",
      "12/12 - 0s - 30ms/step - accuracy: 0.9861 - loss: 0.0471 - val_accuracy: 0.9457 - val_loss: 0.1995\n",
      "Epoch 11/15\n",
      "12/12 - 0s - 35ms/step - accuracy: 0.9972 - loss: 0.0114 - val_accuracy: 0.9348 - val_loss: 0.1992\n",
      "Epoch 12/15\n",
      "12/12 - 0s - 35ms/step - accuracy: 0.9889 - loss: 0.0252 - val_accuracy: 0.9348 - val_loss: 0.1988\n",
      "Epoch 13/15\n",
      "12/12 - 0s - 41ms/step - accuracy: 1.0000 - loss: 0.0096 - val_accuracy: 0.9348 - val_loss: 0.1982\n",
      "Epoch 14/15\n",
      "12/12 - 0s - 35ms/step - accuracy: 0.9834 - loss: 0.0276 - val_accuracy: 0.9348 - val_loss: 0.1972\n",
      "Epoch 15/15\n",
      "12/12 - 1s - 45ms/step - accuracy: 0.9889 - loss: 0.0266 - val_accuracy: 0.9348 - val_loss: 0.1967\n",
      "Model training and fine-tuning completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load the base MobileNetV2 model with pretrained weights- aplha 0.35 works good but may prefer lower later\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=INPUT_SHAPE, alpha=0.35, weights=WEIGHTS_PATH\n",
    ")\n",
    "print(\"base model loaded\")\n",
    "base_model.trainable = True  # True works good\n",
    "\n",
    "# Build the final model\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=INPUT_SHAPE, name='x_input'))\n",
    "last_layer_index = -3\n",
    "model.add(Model(inputs=base_model.inputs, outputs=base_model.layers[last_layer_index].output))\n",
    "model.add(Reshape((-1, model.layers[-1].output.shape[3])))\n",
    "model.add(Dense(8, activation='relu'))  # 8 works good\n",
    "model.add(Dropout(0.2)) # 0.2 works good\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))  # 3 classes (vertical, horizontal, nothing)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "              loss=categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks (optional)\n",
    "callbacks = [\n",
    "    ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_accuracy', mode='max'),\n",
    "    #EarlyStopping(patience=3, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "model.fit(train_dataset, validation_data=validation_dataset, epochs=EPOCHS, verbose=2, callbacks=callbacks)\n",
    "\n",
    "# Fine-tuning the model\n",
    "print(f'Fine-tuning the model for {FINE_TUNE_EPOCHS} epochs...')\n",
    "model = tf.keras.models.load_model('best_model.h5')\n",
    "\n",
    "# Unfreeze the base model layers and freeze layers before the fine-tune layer\n",
    "model_layer_count = len(model.layers)\n",
    "fine_tune_from = math.ceil(model_layer_count * ((100 - FINE_TUNE_PERCENTAGE) / 100))\n",
    "\n",
    "model.trainable = True\n",
    "for layer in model.layers[:fine_tune_from]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile the model after unfreezing\n",
    "model.compile(optimizer=Adam(learning_rate=0.000045),\n",
    "              loss=categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Continue training with fine-tuning\n",
    "model.fit(train_dataset, epochs=FINE_TUNE_EPOCHS, verbose=2, validation_data=validation_dataset, callbacks=callbacks)\n",
    "\n",
    "print(\"Model training and fine-tuning completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9a0370d-85c5-409b-abc9-94dc5dd76724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building custom base model...\n",
      "Training the model...\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 4s - 336ms/step - accuracy: 0.3767 - loss: 9.5524 - val_accuracy: 0.5000 - val_loss: 1.2598\n",
      "Epoch 2/40\n",
      "12/12 - 1s - 56ms/step - accuracy: 0.4875 - loss: 1.1455 - val_accuracy: 0.4239 - val_loss: 1.0024\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 1s - 45ms/step - accuracy: 0.5679 - loss: 0.9305 - val_accuracy: 0.6630 - val_loss: 0.8676\n",
      "Epoch 4/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 0s - 19ms/step - accuracy: 0.6150 - loss: 0.8348 - val_accuracy: 0.6739 - val_loss: 0.8381\n",
      "Epoch 5/40\n",
      "12/12 - 0s - 40ms/step - accuracy: 0.7119 - loss: 0.6858 - val_accuracy: 0.6304 - val_loss: 0.8335\n",
      "Epoch 6/40\n",
      "12/12 - 0s - 41ms/step - accuracy: 0.7479 - loss: 0.6132 - val_accuracy: 0.6630 - val_loss: 0.7620\n",
      "Epoch 7/40\n",
      "12/12 - 1s - 46ms/step - accuracy: 0.7673 - loss: 0.5411 - val_accuracy: 0.6739 - val_loss: 0.7803\n",
      "Epoch 8/40\n",
      "12/12 - 0s - 38ms/step - accuracy: 0.8144 - loss: 0.4451 - val_accuracy: 0.6739 - val_loss: 0.7781\n",
      "Epoch 9/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 1s - 47ms/step - accuracy: 0.8504 - loss: 0.3762 - val_accuracy: 0.7283 - val_loss: 0.7447\n",
      "Epoch 10/40\n",
      "12/12 - 1s - 42ms/step - accuracy: 0.8726 - loss: 0.3284 - val_accuracy: 0.6739 - val_loss: 0.8114\n",
      "Epoch 11/40\n",
      "12/12 - 1s - 42ms/step - accuracy: 0.8947 - loss: 0.2647 - val_accuracy: 0.6739 - val_loss: 0.8734\n",
      "Epoch 12/40\n",
      "12/12 - 0s - 35ms/step - accuracy: 0.9252 - loss: 0.2112 - val_accuracy: 0.6957 - val_loss: 0.7211\n",
      "Epoch 13/40\n",
      "12/12 - 0s - 41ms/step - accuracy: 0.8809 - loss: 0.2344 - val_accuracy: 0.6304 - val_loss: 0.8742\n",
      "Epoch 14/40\n",
      "12/12 - 1s - 46ms/step - accuracy: 0.8975 - loss: 0.2173 - val_accuracy: 0.6304 - val_loss: 0.9440\n",
      "Epoch 15/40\n",
      "12/12 - 0s - 6ms/step - accuracy: 0.9197 - loss: 0.1858 - val_accuracy: 0.6739 - val_loss: 0.8362\n",
      "Epoch 16/40\n",
      "12/12 - 0s - 40ms/step - accuracy: 0.8864 - loss: 0.2035 - val_accuracy: 0.7065 - val_loss: 0.7204\n",
      "Epoch 17/40\n",
      "12/12 - 1s - 44ms/step - accuracy: 0.9280 - loss: 0.1612 - val_accuracy: 0.7065 - val_loss: 0.6913\n",
      "Epoch 18/40\n",
      "12/12 - 1s - 43ms/step - accuracy: 0.9141 - loss: 0.1656 - val_accuracy: 0.6630 - val_loss: 0.9805\n",
      "Epoch 19/40\n",
      "12/12 - 0s - 38ms/step - accuracy: 0.9086 - loss: 0.1741 - val_accuracy: 0.6630 - val_loss: 0.8178\n",
      "Epoch 20/40\n",
      "12/12 - 1s - 43ms/step - accuracy: 0.9280 - loss: 0.1508 - val_accuracy: 0.6957 - val_loss: 0.8853\n",
      "Epoch 21/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 1s - 44ms/step - accuracy: 0.9252 - loss: 0.1414 - val_accuracy: 0.7500 - val_loss: 0.8116\n",
      "Epoch 22/40\n",
      "12/12 - 0s - 40ms/step - accuracy: 0.9363 - loss: 0.1648 - val_accuracy: 0.7174 - val_loss: 0.8432\n",
      "Epoch 23/40\n",
      "12/12 - 1s - 44ms/step - accuracy: 0.9086 - loss: 0.1691 - val_accuracy: 0.7283 - val_loss: 0.7898\n",
      "Epoch 24/40\n",
      "12/12 - 0s - 34ms/step - accuracy: 0.9612 - loss: 0.1017 - val_accuracy: 0.7391 - val_loss: 0.7829\n",
      "Epoch 25/40\n",
      "12/12 - 1s - 44ms/step - accuracy: 0.9557 - loss: 0.1379 - val_accuracy: 0.7391 - val_loss: 0.7644\n",
      "Epoch 26/40\n",
      "12/12 - 0s - 5ms/step - accuracy: 0.9391 - loss: 0.1406 - val_accuracy: 0.6957 - val_loss: 0.7612\n",
      "Epoch 27/40\n",
      "12/12 - 0s - 32ms/step - accuracy: 0.9363 - loss: 0.1508 - val_accuracy: 0.7391 - val_loss: 0.8911\n",
      "Epoch 28/40\n",
      "12/12 - 1s - 44ms/step - accuracy: 0.9612 - loss: 0.1168 - val_accuracy: 0.6739 - val_loss: 1.0610\n",
      "Epoch 29/40\n",
      "12/12 - 1s - 45ms/step - accuracy: 0.9612 - loss: 0.1366 - val_accuracy: 0.7391 - val_loss: 0.8284\n",
      "Epoch 30/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 1s - 53ms/step - accuracy: 0.9474 - loss: 0.1441 - val_accuracy: 0.7609 - val_loss: 0.9154\n",
      "Epoch 31/40\n",
      "12/12 - 1s - 50ms/step - accuracy: 0.9557 - loss: 0.1258 - val_accuracy: 0.7609 - val_loss: 0.9694\n",
      "Epoch 32/40\n",
      "12/12 - 1s - 43ms/step - accuracy: 0.9391 - loss: 0.1208 - val_accuracy: 0.7500 - val_loss: 0.9536\n",
      "Epoch 33/40\n",
      "12/12 - 1s - 45ms/step - accuracy: 0.9474 - loss: 0.1385 - val_accuracy: 0.7391 - val_loss: 0.8181\n",
      "Epoch 34/40\n",
      "12/12 - 1s - 42ms/step - accuracy: 0.9584 - loss: 0.1367 - val_accuracy: 0.7174 - val_loss: 0.8067\n",
      "Epoch 35/40\n",
      "12/12 - 1s - 43ms/step - accuracy: 0.9668 - loss: 0.1049 - val_accuracy: 0.7391 - val_loss: 0.8764\n",
      "Epoch 36/40\n",
      "12/12 - -0s - -3276us/step - accuracy: 0.9695 - loss: 0.1173 - val_accuracy: 0.6957 - val_loss: 1.0640\n",
      "Epoch 37/40\n",
      "12/12 - 0s - 38ms/step - accuracy: 0.9418 - loss: 0.1499 - val_accuracy: 0.7391 - val_loss: 1.0510\n",
      "Epoch 38/40\n",
      "12/12 - 1s - 49ms/step - accuracy: 0.9529 - loss: 0.1100 - val_accuracy: 0.7391 - val_loss: 0.9813\n",
      "Epoch 39/40\n",
      "12/12 - 1s - 42ms/step - accuracy: 0.9806 - loss: 0.0883 - val_accuracy: 0.7500 - val_loss: 0.9732\n",
      "Epoch 40/40\n",
      "12/12 - 0s - 38ms/step - accuracy: 0.9778 - loss: 0.0988 - val_accuracy: 0.6848 - val_loss: 1.1049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning the model for 15 epochs...\n",
      "Epoch 1/15\n",
      "12/12 - 3s - 213ms/step - accuracy: 0.9695 - loss: 0.1178 - val_accuracy: 0.7609 - val_loss: 0.9173\n",
      "Epoch 2/15\n",
      "12/12 - 6s - 493ms/step - accuracy: 0.9501 - loss: 0.1438 - val_accuracy: 0.7609 - val_loss: 0.9188\n",
      "Epoch 3/15\n",
      "12/12 - -5s - -445929us/step - accuracy: 0.9612 - loss: 0.1314 - val_accuracy: 0.7609 - val_loss: 0.9207\n",
      "Epoch 4/15\n",
      "12/12 - 1s - 48ms/step - accuracy: 0.9391 - loss: 0.1699 - val_accuracy: 0.7500 - val_loss: 0.9219\n",
      "Epoch 5/15\n",
      "12/12 - 0s - 37ms/step - accuracy: 0.9612 - loss: 0.1177 - val_accuracy: 0.7500 - val_loss: 0.9230\n",
      "Epoch 6/15\n",
      "12/12 - 1s - 44ms/step - accuracy: 0.9640 - loss: 0.1160 - val_accuracy: 0.7500 - val_loss: 0.9242\n",
      "Epoch 7/15\n",
      "12/12 - 1s - 45ms/step - accuracy: 0.9640 - loss: 0.1211 - val_accuracy: 0.7500 - val_loss: 0.9260\n",
      "Epoch 8/15\n",
      "12/12 - 0s - 41ms/step - accuracy: 0.9529 - loss: 0.1397 - val_accuracy: 0.7500 - val_loss: 0.9272\n",
      "Epoch 9/15\n",
      "12/12 - 1s - 45ms/step - accuracy: 0.9557 - loss: 0.1565 - val_accuracy: 0.7500 - val_loss: 0.9283\n",
      "Epoch 10/15\n",
      "12/12 - 1s - 42ms/step - accuracy: 0.9778 - loss: 0.1224 - val_accuracy: 0.7500 - val_loss: 0.9291\n",
      "Epoch 11/15\n",
      "12/12 - 0s - 41ms/step - accuracy: 0.9474 - loss: 0.1442 - val_accuracy: 0.7500 - val_loss: 0.9300\n",
      "Epoch 12/15\n",
      "12/12 - 0s - 40ms/step - accuracy: 0.9640 - loss: 0.1432 - val_accuracy: 0.7500 - val_loss: 0.9313\n",
      "Epoch 13/15\n",
      "12/12 - 0s - 4ms/step - accuracy: 0.9640 - loss: 0.1264 - val_accuracy: 0.7500 - val_loss: 0.9319\n",
      "Epoch 14/15\n",
      "12/12 - 0s - 33ms/step - accuracy: 0.9612 - loss: 0.1264 - val_accuracy: 0.7500 - val_loss: 0.9331\n",
      "Epoch 15/15\n",
      "12/12 - 0s - 41ms/step - accuracy: 0.9723 - loss: 0.1076 - val_accuracy: 0.7500 - val_loss: 0.9343\n",
      "Model training and fine-tuning completed successfully.\n"
     ]
    }
   ],
   "source": [
    "## My beautiful custom model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Reshape, InputLayer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "print(\"building custom base model...\")\n",
    "base_model = Sequential()\n",
    "base_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=INPUT_SHAPE))\n",
    "base_model.add(MaxPooling2D((2, 2)))\n",
    "base_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "base_model.add(MaxPooling2D((2, 2)))\n",
    "base_model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "base_model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add the custom layers for the final model\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=INPUT_SHAPE, name='x_input'))\n",
    "model.add(base_model)  # Use the custom CNN base model\n",
    "model.add(Flatten())  # Flatten the output of the base model\n",
    "model.add(Dense(32, activation='relu'))  # Dense layer with 128 neurons\n",
    "model.add(Dropout(0.2))  # Dropout layer to avoid overfitting\n",
    "model.add(Dense(3, activation='softmax'))  # Output layer with 3 classes (vertical, horizontal, nothing)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "              loss=categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks (optional)\n",
    "callbacks = [\n",
    "    ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_accuracy', mode='max'),\n",
    "    # EarlyStopping(patience=3, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the model...\")\n",
    "model.fit(train_dataset, validation_data=validation_dataset, epochs=EPOCHS, verbose=2, callbacks=callbacks)\n",
    "\n",
    "# Fine-tuning the model\n",
    "print(f'Fine-tuning the model for {FINE_TUNE_EPOCHS} epochs...')\n",
    "model = tf.keras.models.load_model('best_model.h5')\n",
    "\n",
    "# Unfreeze the custom layers for fine-tuning\n",
    "model.trainable = True\n",
    "for layer in model.layers[:len(model.layers)-2]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile the model after unfreezing\n",
    "model.compile(optimizer=Adam(learning_rate=0.000045),\n",
    "              loss=categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Continue training with fine-tuning\n",
    "model.fit(train_dataset, epochs=FINE_TUNE_EPOCHS, verbose=2, validation_data=validation_dataset, callbacks=callbacks)\n",
    "\n",
    "print(\"Model training and fine-tuning completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "548f87a1-a9ea-4d81-9fcb-0b47439b9b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpput8cgfr/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpput8cgfr/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpput8cgfr'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 96, 96, 1), dtype=tf.float32, name='x_input')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  140303567871952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140302023194384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140302023190544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140302023186320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140302023193616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140302023192464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140302023184016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140302023189392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140302023191696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140302023183248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1737508447.868421   94864 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1737508447.868467   94864 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-01-21 17:14:07.868602: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpput8cgfr\n",
      "2025-01-21 17:14:07.869056: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-01-21 17:14:07.869062: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpput8cgfr\n",
      "2025-01-21 17:14:07.872853: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-01-21 17:14:07.900200: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpput8cgfr\n",
      "2025-01-21 17:14:07.907219: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 38619 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# dont use this\n",
    "model = tf.keras.models.load_model('best_model.h5')\n",
    "\n",
    "# Convert the model to TFLite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model to a file\n",
    "with open('model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec693803-689a-4bb7-9bff-2322e4ccf14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpejanyv66/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpejanyv66/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpejanyv66'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 96, 96, 1), dtype=tf.float32, name='x_input')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  140301757982544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306652362704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306652355024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140301757984464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306652359440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306652355216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306652350992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306652357136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306652351184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306652362512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306652360976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306652513872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306652522320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306652360784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306652520016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306652516176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306652521552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306652527504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306652514064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306652523856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306652526160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650633360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650637200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306652518480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306652517712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650630672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650640272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650643920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650632592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650634896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650629904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650786576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650790416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650640464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650642576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650781968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650777744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650791184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650779856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650788880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650775824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650781200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650980688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650779088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650786768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650973200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650978384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650986832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650979152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650984528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650982608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650982416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650978576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650975312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306650982224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306651147600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306651137808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306651149712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306651142032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306651143568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306651151056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306651145872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306651137616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306651141264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140306651151248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140301635015440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140301635021776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140301635018512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140301635014288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140301635019088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140301635010640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140301635011216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140301635013136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140301635013328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140301635021968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140301635015824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140301635019664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140301635021584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140301635024656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140301635015056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140301635013712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140301635025424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140301635020048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140301635020624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140301635020816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140301635025040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140301635012368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586379152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140301635017744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140301635013904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586381456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586380880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586378384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586383760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586381072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586387408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586380112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586382416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586386640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586378000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586391248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586383952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586386256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586390480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586378960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586378576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586392400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586392976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586393936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586384720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586388560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863889296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863885456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863891792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863879696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863889104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863892752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863891024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863884496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863881808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863893328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140305109357136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140305109356560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863892176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140305109367312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140305109367888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140305109355600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863406288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140305109364624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140305109354256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863411280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863413008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140309746125136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863409744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863415120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140309746129936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140309746125712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140309746125904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140309746128784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140309746130704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863033872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863028496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863026000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863037136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863025232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863034256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140309335526480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140309335530704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140309335525712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140309335533392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140309335523792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140309335142288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140309335138448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140309335145936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140309335131536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140309335141136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863120016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863108688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863122512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863108112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863120208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863118288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863121936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863118096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863108880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863112528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140309746439504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140309746438352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863116176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140309746449488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140309746446032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303157981264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303157982416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140309746442960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303157980304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303157978960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303157982608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303157980688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303157976848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303157983184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303157976272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303157973584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303157976656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303157985104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303157980880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303157983568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303585202960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303585198736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303157975312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303157975120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303585200848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303585206800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303585203728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303585202000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303585204496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303585207952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303585198160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303585204304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303585200464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303585200656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140309790759376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140309790762448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140309790761296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140309790761680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140309790765520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303583978960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140309790756304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586411152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140309790754576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140309790761104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586415760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586420176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586414608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586420560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586411344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586422096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586424208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586421136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586419984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586419024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586425936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586421328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586425552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586423824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586419792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303586419600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863838224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863840144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863839760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863832272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863843216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863839184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863829392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863835152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863837456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863843408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863365776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863363472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863842832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863828432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863365968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863356368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863355216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863354064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863368656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863357136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303564054480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303564052368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863357904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140308863353488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303564055632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303564058320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303564054672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303564058704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303564047376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303564059472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303564062160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303564058512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303564062544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303564051600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303564059088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303564050448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303564751888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140303564756880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/rtill/AI-venv/AIvenv/lib/python3.12/site-packages/tensorflow/lite/python/convert.py:997: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "W0000 00:00:1737512330.577733   94864 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1737512330.578062   94864 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-01-21 18:18:50.579033: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpejanyv66\n",
      "2025-01-21 18:18:50.587175: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-01-21 18:18:50.587199: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpejanyv66\n",
      "2025-01-21 18:18:50.676099: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-01-21 18:18:51.177025: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpejanyv66\n",
      "2025-01-21 18:18:51.292102: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 713085 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INT8 quantized model saved as 'model_int8.tflite'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('best_model_bm_trainable_val_acc_95p.h5')\n",
    "\n",
    "# Create the TFLiteConverter object\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Enable INT8 quantization\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Specify representative dataset for proper quantization\n",
    "# Define a representative dataset generator function\n",
    "def representative_data_gen():\n",
    "    for _ in range(100):  # Provide 100 representative samples\n",
    "        # Use sample images from your dataset resized to the expected input shape\n",
    "        # Replace with actual preprocessed images as numpy arrays\n",
    "        yield [tf.random.uniform(shape=(1, 96, 96, 1), minval=0, maxval=1, dtype=tf.float32)]\n",
    "\n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "# Ensure the model is fully quantized to INT8\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "# Specify that both input and output tensors should be INT8\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "# Convert the model to TFLite format\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model to a file\n",
    "with open('model_int8.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"INT8 quantized model saved as 'model_int8.tflite'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
